{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 0.1.0.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import azureml.core\n",
    "from azureml.core.runconfig import JarLibrary\n",
    "from azureml.core.compute import ComputeTarget, DatabricksCompute\n",
    "from azureml.exceptions import ComputeTargetException\n",
    "from azureml.core import Workspace, Experiment\n",
    "from azureml.pipeline.core import Pipeline, PipelineData\n",
    "from azureml.pipeline.steps import DatabricksStep\n",
    "from azureml.core.datastore import Datastore\n",
    "from azureml.data.data_reference import DataReference\n",
    "\n",
    "# Check core SDK version number\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_id = \"\"\n",
    "resource_group = \"\"\n",
    "workspace_name = \"\"\n",
    "databricks_compute_name = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Warning: Falling back to use azure cli login credentials.\n",
      "If you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\n",
      "Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n"
     ]
    }
   ],
   "source": [
    "ws = Workspace.get(\n",
    "    name=workspace_name,\n",
    "    subscription_id=subscription_id,\n",
    "    resource_group=resource_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "databricks_compute = DatabricksCompute(workspace=ws, name=databricks_compute_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One time setup: Install databricks CLI and configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: databricks-cli in c:\\users\\akvasude\\appdata\\local\\continuum\\miniconda3\\envs\\cli_dev\\lib\\site-packages (0.14.0)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in c:\\users\\akvasude\\appdata\\local\\continuum\\miniconda3\\envs\\cli_dev\\lib\\site-packages (from databricks-cli) (0.8.2)\n",
      "Requirement already satisfied: click>=6.7 in c:\\users\\akvasude\\appdata\\local\\continuum\\miniconda3\\envs\\cli_dev\\lib\\site-packages (from databricks-cli) (6.7)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\akvasude\\appdata\\local\\continuum\\miniconda3\\envs\\cli_dev\\lib\\site-packages (from databricks-cli) (1.11.0)\n",
      "Requirement already satisfied: requests>=2.17.3 in c:\\users\\akvasude\\appdata\\local\\continuum\\miniconda3\\envs\\cli_dev\\lib\\site-packages (from databricks-cli) (2.19.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\akvasude\\appdata\\local\\continuum\\miniconda3\\envs\\cli_dev\\lib\\site-packages (from requests>=2.17.3->databricks-cli) (2018.11.29)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\akvasude\\appdata\\local\\continuum\\miniconda3\\envs\\cli_dev\\lib\\site-packages (from requests>=2.17.3->databricks-cli) (3.0.4)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in c:\\users\\akvasude\\appdata\\local\\continuum\\miniconda3\\envs\\cli_dev\\lib\\site-packages (from requests>=2.17.3->databricks-cli) (2.7)\n",
      "Requirement already satisfied: urllib3<1.24,>=1.21.1 in c:\\users\\akvasude\\appdata\\local\\continuum\\miniconda3\\envs\\cli_dev\\lib\\site-packages (from requests>=2.17.3->databricks-cli) (1.23)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "twisted 18.7.0 requires PyHamcrest>=1.9.0, which is not installed.\n",
      "msftkube 1.0.1598662 has requirement applicationinsights==0.11.5, but you'll have applicationinsights 0.11.9 which is incompatible.\n",
      "msftkube 1.0.1598662 has requirement urllib3==1.22, but you'll have urllib3 1.23 which is incompatible.\n",
      "azureml-sdk 0.1.0.1060109 has requirement azureml-core==0.1.0.1060109, but you'll have azureml-core 0.1.0.0 which is incompatible.\n",
      "azureml-sdk 0.1.0.1060109 has requirement azureml-train==0.1.0.1060109, but you'll have azureml-train 0.1.0.0 which is incompatible.\n",
      "azureml-requirements 0.1.0.888002 has requirement azureml-core==0.1.0.888002, but you'll have azureml-core 0.1.0.0 which is incompatible.\n",
      "azureml-requirements 0.1.0.888002 has requirement azureml-train==0.1.0.888002, but you'll have azureml-train 0.1.0.0 which is incompatible.\n",
      "azureml-contrib-widgets 0.1.0.1060109 has requirement azureml-core==0.1.0.1060109, but you'll have azureml-core 0.1.0.0 which is incompatible.\n",
      "azureml-contrib-widgets 0.1.0.1060109 has requirement azureml-train-core==0.1.0.1060109, but you'll have azureml-train-core 0.1.0.0 which is incompatible.\n",
      "azureml-contrib-tensorboard 0.1.0.1060109 has requirement azureml-core==0.1.0.1060109, but you'll have azureml-core 0.1.0.0 which is incompatible.\n",
      "azure-datalake-store 0.0.19 has requirement msrest~=0.4.5, but you'll have msrest 0.5.4 which is incompatible.\n",
      "azure-cli-appservice 0.1.32 has requirement azure-mgmt-containerregistry==2.0.0, but you'll have azure-mgmt-containerregistry 2.8.0 which is incompatible.\n",
      "azure-cli-acr 2.0.24 has requirement azure-mgmt-containerregistry==2.0.0, but you'll have azure-mgmt-containerregistry 2.8.0 which is incompatible.\n",
      "azure-cli-ml 0.1.0.0 has requirement docker>=3.7.2, but you'll have docker 3.3.0 which is incompatible.\n",
      "azure-cli-ml 0.1.0.0 has requirement msrest>=0.6.6, but you'll have msrest 0.5.4 which is incompatible.\n",
      "azure-cli-ml 0.1.0.0 has requirement pyyaml>=5.1.0, but you'll have pyyaml 4.2b4 which is incompatible.\n",
      "azure-cli-ml 0.1.0.0 has requirement requests>=2.21.0, but you'll have requests 2.19.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install databricks-cli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure CLI\n",
    "\n",
    "> Run `dbfs configure --token` at command line to setup authentication. You'll need to specify Databricks URL and Personal Access Token. This link has details: https://docs.databricks.com/dev-tools/cli/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload files from local computer to DBFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path = \".\\code\"\n",
    "dbfs_path = \"dbfs:/UploadTest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this if you need to delete existing DBFS folder\n",
    "# !dbfs rm -r {dbfs_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\code\\hello.py -> dbfs:/UploadTest/hello.py\n"
     ]
    }
   ],
   "source": [
    "!dbfs cp -r {local_path} {dbfs_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the file that was uploaded to DBFS in DatabricksStep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbfs:/UploadTest/hello.py\n"
     ]
    }
   ],
   "source": [
    "python_script_path = dbfs_path + \"/hello.py\"  # append name of the entry script\n",
    "print(python_script_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbPythonInDbfsStep = DatabricksStep(\n",
    "    name=\"DBPythonInDBFS\",\n",
    "    run_name='DB_Python_demo',\n",
    "    compute_target=databricks_compute,\n",
    "    python_script_path=python_script_path,\n",
    "    python_script_params={'arg1', 'arg2'},\n",
    "    num_workers=1,\n",
    "    allow_reuse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [dbPythonInDbfsStep]\n",
    "pipeline = Pipeline(workspace=ws, steps=steps)\n",
    "pipeline_run = Experiment(ws, 'DB_Python_demo').submit(pipeline)\n",
    "pipeline_run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cli_dev]",
   "language": "python",
   "name": "conda-env-cli_dev-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
